---
title: "Case Study: Forecasting COVID deaths"
output: html_document
date: "2024-08-31"
---

# Packages and data

```{r load-libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(epidatasets)
library(epidatr)
library(epiprocess)
library(epipredict)

theme_set(theme_bw())
```

Download finalized COVID cases and deaths for California.

```{r download-data}
cases <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_incidence_num",
  time_type = "day",
  geo_type = "state",
  time_values = epirange(20200401, 20220101),
  geo_values = "ca") %>%
  select(geo_value, time_value, cases = value)

deaths <- pub_covidcast(
  source = "jhu-csse",
  signals = "deaths_incidence_num",
  time_type = "day",
  geo_type = "state",
  time_values = epirange(20200401, 20220101),
  geo_values = "ca") %>%
  select(geo_value, time_value, deaths = value)
```

# Pre-process and visualize data

Join the dataframes and create `epi_df`.

```{r join}
ca <- left_join(cases, deaths, by = c("time_value", "geo_value")) %>%
  as_epi_df()

ca
```

Scale cases and deaths by population. State population data
is available inside `{epipredict}` as `state_census`.

```{r population-scaling}
ca <- left_join(
  x = ca,
  y = state_census %>% select(pop, abbr),
  by = c("geo_value" = "abbr"))

ca <- ca %>%
  mutate(cases = cases / pop * 1e5, # cases / 100K
         deaths = deaths / pop * 1e5) %>% # deaths / 100K
  select(-pop)
```

Now, use `epi_slide_mean()`, to calculate trailing 7 day averages of cases and deaths.

```{r trailing-averages}
ca <- ca %>%
  epi_slide_mean(c(cases, deaths), .window_size = 7) %>%
  select(-cases, -deaths) %>%
  rename(cases = cases_7dav, deaths = deaths_7dav)
```

Visualize the data.

```{r plot-rates}
ca %>%
  pivot_longer(cols = c(cases, deaths), names_to = 'Signal') %>%
  ggplot(aes(time_value, value, col = Signal)) +
  geom_line() +
  xlab('Date') +
  ylab('Rates (per 100k people)') +
  facet_wrap(~Signal, scales = 'free') +
  theme(legend.position = "none")
```

Notice that some of the COVID death rates are below 0.
Let's impute these values to be 0.

```{r impute-negative-rates}
ca$deaths[ca$deaths < 0] <- 0
```

Overlay cases and deaths on the same plot.

```{r nicer-plot-rates}
# Handy function to produce a transformation from one range to another
trans = function(x, from_range, to_range) {
  (x - from_range[1]) / (from_range[2] - from_range[1]) *
    (to_range[2] - to_range[1]) + to_range[1]
}

# Compute ranges of the two signals, and transformations in b/w them
range1 = ca %>% select(cases) %>% range()
range2 = ca %>% select(deaths) %>% range()
trans12 = function(x) trans(x, range1, range2)
trans21 = function(x) trans(x, range2, range1)

ggplot(ca %>%
         mutate(deaths = trans21(deaths)) %>%
         pivot_longer(cols = c(cases, deaths), names_to = 'name'),
       aes(x = time_value, y = value)) +
  geom_line(aes(color = name)) +
  scale_color_manual(values = palette()[c(2,4)]) +
  scale_y_continuous(
    name = "Reported Covid-19 cases per 100k people",
    limits = range1,
    sec.axis = sec_axis(
      trans = trans12,
      name = "Reported Covid-19 deaths per 100k people")) +
  labs(title = "Covid-19 cases and deaths in California", x = "Date") +
  theme(legend.position = "bottom", legend.title = element_blank())

```

Split data into training (before 2021-03-01) and testing set (after 2021-03-01).

```{r train-test-split}
t0_date <- as.Date('2021-03-01') #split date

train <- ca %>% filter(time_value <= t0_date)
test <- ca %>% filter(time_value > t0_date)

t0 <- nrow(train)  #split index
```

# Choose and create a lagged predictor

Check which lag leads to highest correlation between cases and deaths on the
training set.

```{r correlations}
# look at cases and deaths (where we move deaths forward by 1, 2, ..., 35 days)
lags = 1:35
cor_deaths_cases <- lapply(lags,
                             function(x) epi_cor(train, deaths, cases,
                                                 cor_by = geo_value, dt1 = x))

cor_deaths_cases <- list_rbind(cor_deaths_cases, names_to = 'Lag')

# lag leading to maximum correlation
k <- which.max(cor_deaths_cases$cor)

cor_deaths_cases %>%
  ggplot(aes(Lag, cor)) +
  geom_point() +
  geom_line() +
  labs(x = "Lag", y = "Correlation") +
  geom_vline(xintercept = k) +
  ggtitle('Correlation between cases and deaths by lag')
```

We will use lagged COVID cases to predict COVID deaths.
COVID cases will be lagged by `r k`.

```{r lag-cases}
ca$lagged_cases <- dplyr::lag(ca$cases, n = k)
train <- ca %>% filter(time_value <= t0_date)
test <- ca %>% filter(time_value > t0_date)
```

Let's plot COVID deaths versus lagged COVID cases to check that the
relationship is approximately linear.

```{r plot-deaths-and-lagged-cases}
ggplot(train, aes(lagged_cases, deaths)) +
  geom_point(alpha = .5) +
  labs(x = "Lagged cases", y = "Deaths")
```


# Lagged linear regression

Perform linear regression of deaths on lagged cases using training data.

```{r lagged-lm}
reg_lagged = lm(deaths ~ lagged_cases, data = train)
coef(reg_lagged)
```

Plot again COVID deaths versus lagged COVID cases with regression line.

```{r plot-reg-line}
ggplot(train, aes(lagged_cases, deaths)) +
  geom_point(alpha = .5) +
  geom_abline(intercept = coef(reg_lagged)[1], slope = coef(reg_lagged)[2],
              col = 'red') +
  labs(x = "Lagged cases", y = "Deaths") +
  ggtitle("Deaths vs cases (lagged by 26 days) with regression line")

```


## Training error

Let's compute the MSE, MAE, MAPE, and MASE on the training set.

```{r error functions}
MSE <- function(truth, prediction) {
  mean((truth - prediction)^2)}

MAE <- function(truth, prediction) {
  mean(abs(truth - prediction))}

MAPE <- function(truth, prediction) {
  100 * mean(abs(truth - prediction) / truth)}

MASE <- function(truth, prediction) {
  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}
```

```{r training-error}
pred_train <- predict(reg_lagged, train)
train$pred_train <- pred_train

errors <- data.frame("MSE" = MSE(train$deaths[-seq_len(7+k-1)], pred_train[-seq_len(7+k-1)]),
                     "MAE"= MAE(train$deaths[-seq_len(7+k-1)], pred_train[-seq_len(7+k-1)]),
                     "MAPE" = MAPE(train$deaths[-seq_len(7+k-1)], pred_train[-seq_len(7+k-1)]),
                     "MASE" = MASE(train$deaths[-seq_len(7+k-1)], pred_train[-seq_len(7+k-1)]),
                     row.names = "training")
errors
```

The predictions on the training set track the observed death rates quite closely.

```{r plot-train-predictions}
train %>%
  mutate(observed = deaths, predicted = pred_train) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "Regression with a lagged predictor: training",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


## Split-sample error

Let's compute the MSE, MAE, MAPE, and MASE on the test set.
As expected, the errors on the test set are much larger than the errors on the
training set.

Notice that the MAPE does not have a finite value because there are some 0s in
the denominator.

```{r test-error}
test$pred_test <- predict(reg_lagged, newdata = test)

errors <- rbind(errors,
                data.frame("MSE" = MSE(test$deaths, test$pred_test),
                           "MAE"= MAE(test$deaths, test$pred_test),
                           "MAPE" = MAPE(test$deaths, test$pred_test),
                           "MASE" = MASE(test$deaths, test$pred_test),
                           row.names = "split-sample"))
errors
```

Let's plot the predictions on the test set.
They look fine: the model under-predicts at the beginning, and then
over-predicts for the rest of the time.

```{r plot-test-predictions}
test %>%
  mutate(observed = deaths, predicted = pred_test) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "Regression with a lagged predictor: test",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

--------------------------------------------------------------------------------

AFTERNOON

We can also perform split-sample using `{epipredict}`.

```{r epipredict-lagged-reg}
head(test)

epi_reg_lagged <- arx_forecaster(epi_data = train %>% as_epi_df(),
                                 outcome = "deaths",
                                 predictors = "cases",
                                 trainer = linear_reg() %>% set_engine("lm"),
                                 args_list = arx_args_list(lags = k-1,
                                                           ahead = 1L))

extract_fit_parsnip(epi_reg_lagged$epi_workflow)
```

--------------------------------------------------------------------------------

## Time-series cross-validation

We will now perform time-series cross-validation fitting the model on:

- all the past data up to the forecasting time
- a trailing window of data up to the forecasting time

We set the trailing window to have size = 30,
and we perform 1-step-ahead predictions.

```{r time-series-cv}
n <- nrow(ca)
pred_all_past = pred_trailing <- rep(NA, length = n - t0)
w <- 30 # trailing window size

for (t in (t0+1):n) {
  reg_all_past = lm(deaths ~ lagged_cases, data = ca,
                    #subset = (1:n) <= (t-k))
                    subset = (1:n) <= (t-1))
  reg_trailing = lm(deaths ~ lagged_cases, data = ca,
                    #subset = (1:n) <= (t-k) & (1:n) > (t-k-w))
                    subset = (1:n) <= (t-1) & (1:n) > (t-1-w))
  pred_all_past[t-t0] = predict(reg_all_past, newdata = data.frame(ca[t, ]))
  pred_trailing[t-t0] = predict(reg_trailing, newdata = data.frame(ca[t, ]))
}

test$pred_cv <- pred_all_past
test$pred_trailing_cv <- pred_trailing
```

We compute the cross-validated error when using all the past data up to the
forecasting time. Since we are refitting the model as new data come in, the
error (under all metrics) is slightly smaller than when using a split-sample
approach, but is still not as small as when we compute it on the training data.

```{r cv-error}
errors <- rbind(errors,
                data.frame("MSE" = MSE(test$deaths, pred_all_past),
                           "MAE"= MAE(test$deaths, pred_all_past),
                           "MAPE" = MAPE(test$deaths, pred_all_past),
                           "MASE" =  MASE(test$deaths, pred_all_past),
                           row.names = "time series CV"))
errors
```

The cross-validated error obtained when using a trailing window is much smaller
than all the other errors previously obtained, under all metrics.
This can be explained by the fact that the relationship between the predictor
and the outcome changes over time, and therefore using a short recent
window of data to get linear regression estimates can improve the predictions.


```{r cv-trailing-error}
errors <- rbind(errors,
                data.frame("MSE" = MSE(test$deaths, pred_trailing),
                           "MAE"= MAE(test$deaths, pred_trailing),
                           "MAPE" = MAPE(test$deaths, pred_trailing),
                           "MASE" = MASE(test$deaths, pred_trailing),
                           row.names = "time series CV + trailing"))
errors
```

We plot the 1-step-ahead predictions obtained by the model fitted on all past
data and on trailing windows. The latter tracks the observed deaths quite well.

```{r plot-cv-predictions}
test %>%
  mutate(observed = deaths,
         `predicted (CV)` = pred_cv,
         `predicted (trailing + CV)` = pred_trailing_cv) %>%
  pivot_longer(cols = c(observed, `predicted (CV)`, `predicted (trailing + CV)`),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "Regression with a lagged predictor: time-series cross-validation",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

--------------------------------------------------------------------------------

AFTERNOON

The predictions we obtained by manually lagging `cases` and using `lm` within
`for` loops can be equivalently obtained via `{epipredict}`. The latter gives
a more user-friendly and straightforward way to obtain the predictions.

The approach with trailing window is reported next.

```{r epipredict-cv-trailing}
# specify the forecast dates
fc_time_values <- seq(
  from = t0_date,
  to = tail(ca$time_value, 1) - 1,
  by = "1 day"
)

# slide an arx_forecaster with appropriate outcome, predictions, lags,
# and trailing window
epi_pred_cv_trailing <- epi_slide(
  ca,
  ~ arx_forecaster(epi_data = .x,
                   outcome = "deaths",
                   predictors = "cases",
                   trainer = linear_reg() %>% set_engine("lm"),
                   args_list = arx_args_list(lags = k-1, ahead = 1L)
                   )$predictions,
  # notice that `.window_size` is not simply equal to w. That's because previously,
  # when considering a window from t to t+w-1, we had access to y_t, ..., y_{t+w-1}
  # and also to x_{t-k}, ..., x_{t+w-1-k}. (That's because of how we structured
  # the dataframe after manually lagging x.) So we were cheating by saying that
  # the trailing window had length w, as its actual size was (t+w-1)-(t-k)+1 = w+k!
  .window_size = w + k,
  .ref_time_values = fc_time_values,
  .new_col_name = "fc"
) |>
  # split tibble-type column `fc` into multiple columns with names prefixed by `fc_`:
  unpack(fc, names_sep = "_")

# they match exactly
head(epi_pred_cv_trailing %>% select(fc_.pred, fc_target_date))
head(test %>% select(pred_trailing_cv, time_value))
```

The method fitting on all past data up to the forecasting date can be
implemented by changing `.before = Inf` in `epi_slide`.

```{r epipredict-cv}
# slide an arx_forecaster with appropriate outcome, predictions and lags
epi_pred_cv <- epi_slide(
  ca,
  ~ arx_forecaster(epi_data = .x,
                   outcome = "deaths",
                   predictors = "cases",
                   trainer = linear_reg() %>% set_engine("lm"),
                   args_list = arx_args_list(lags = k-1, ahead = 1L)
                   )$predictions,
  .before = Inf,
  .ref_time_values = fc_time_values,
  .new_col_name = "fc"
) |>
  unpack(fc, names_sep = "_")

# they match exactly
head(epi_pred_cv %>% select(fc_.pred, fc_target_date))
head(test %>% select(pred_cv, time_value))
```

Predicting 7 days ahead:

```{r epipredict-cv-7ahead}
n <- nrow(ca)
pred_all_past <- rep(NA, length = n - t0)
n_ahead <- 7

for (t in (t0+1):n) {
  reg_all_past = lm(deaths ~ lagged_cases, data = ca,
                    subset = (1:n) <= (t-n_ahead))
  pred_all_past[t-t0] = predict(reg_all_past, newdata = data.frame(ca[t, ]))
}

test$pred_cv_7 <- pred_all_past


fc_time_values_7 <- seq(
  from = as.Date("2021-02-23"),
  to = as.Date("2021-12-25"),
  by = "1 day"
)

epi_pred_cv_7 <- epi_slide(
  ca,
  ~ arx_forecaster(epi_data = .x,
                   outcome = "deaths",
                   predictors = "cases",
                   trainer = linear_reg() %>% set_engine("lm"),
                   args_list = arx_args_list(lags = k-n_ahead, ahead = n_ahead)
                   )$predictions,
  .before = Inf,
  .ref_time_values = fc_time_values_7,
  .new_col_name = "fc"
) |>
  unpack(fc, names_sep = "_")

# they match
head(epi_pred_cv_7 %>% select(fc_.pred, fc_target_date))
head(test %>% select(pred_cv_7, time_value))

all(test$time_value == epi_pred_cv_7$fc_target_date)
all(test$pred_cv_7 == epi_pred_cv_7$fc_.pred)

```

--------------------------------------------------------------------------------

# AR model

We now consider a different model. We disregard `cases`, and only use past
`deaths` to predict future `deaths`. Let's check which lag leads to largest
correlation between deaths and lagged deaths.

```{r auto-cor-deaths}
lags <- 1:8
auto_cor_deaths <- lapply(lags,
                          function(x) epi_cor(train, deaths, deaths,
                                              cor_by = geo_value, dt1 = x))

auto_cor_deaths <- list_rbind(auto_cor_deaths, names_to = 'Lag')

auto_cor_deaths %>%
  ggplot(aes(Lag, cor)) +
  geom_point() +
  geom_line() +
  labs(x = "Lag", y = "Correlation") +
  ggtitle('Auto-correlation for deaths by lag')
```

We will consider an AR model where we predict `deaths` using `lagged_deaths`
which lags the former by 1. That is

$y_t \approx \beta_0 + \beta_1 y_{t-1}$

```{r lag-deaths}
ca$lagged_deaths <- dplyr::lag(ca$deaths, n = 1)
```

```{r train/test-ar}
train_ar <- ca %>% filter(time_value <= t0_date)
test_ar <- ca %>% filter(time_value > t0_date)
```

Let's plot COVID deaths versus lagged COVID deaths to check that the
relationship is approximately linear.

```{r ar-plot-deaths-and-lagged-cases}
ggplot(train_ar, aes(lagged_deaths, deaths)) +
  geom_point(alpha = .5) +
  labs(x = "Lagged deaths", y = "Deaths")
```


Perform linear regression of deaths on lagged deaths using training data.

**Note**: the intercept is approximately 0 and the coefficient is approximately 1.
This means that we are naively predicting the number of deaths tomorrow with the
number of deaths observed today.

```{r ar-lm}
ar_fit = lm(deaths ~ lagged_deaths, data = train_ar)
coef(ar_fit)
```

Plot again COVID deaths versus lagged COVID cases with regression line.

```{r plot-ar-fit-line}
ggplot(train_ar, aes(lagged_deaths, deaths)) +
  geom_point(alpha = .5) +
  geom_abline(intercept = coef(ar_fit)[1], slope = coef(ar_fit)[2],
              col = 'red') +
  labs(x = "Lagged deaths", y = "Deaths") +
  ggtitle("Deaths vs lagged deaths with regression line")

```


## Training error

Let's compute the MSE, MAE, MAPE, and MASE on the training set.

```{r ar-training-error}
pred_train <- predict(ar_fit)

train_ar$pred_train <- c(NA, pred_train)

errors_ar <- data.frame("MSE" = MSE(train_ar$deaths[-1], pred_train),
                        "MAE"= MAE(train_ar$deaths[-1], pred_train),
                        "MAPE" = MAPE(train_ar$deaths[-1], pred_train),
                        "MASE" = MASE(train_ar$deaths[-1], pred_train),
                        row.names = "training")
errors_ar
```


```{r ar-plot-train-predictions}
train_ar %>%
  mutate(observed = deaths, predicted = pred_train) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "AR: training",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


## Split-sample error

Let's compute the MSE, MAE, MAPE, and MASE on the test set.
Here, the test errors are very similar to the training errors.

Notice that the MAPE does not have a finite value because there are some 0s in
the denominator.

```{r ar-test-error}
test_ar$pred_test <- predict(ar_fit, newdata = test_ar)

errors_ar <- rbind(errors_ar,
                  data.frame("MSE" = MSE(test_ar$deaths, test_ar$pred_test),
                             "MAE"= MAE(test_ar$deaths, test_ar$pred_test),
                             "MAPE" = MAPE(test_ar$deaths, test_ar$pred_test),
                             "MASE" = MASE(test_ar$deaths, test_ar$pred_test),
                             row.names = "split-sample"))
errors_ar
```

Let's plot the predictions on the test set.

```{r ar-plot-test-predictions}
test_ar %>%
  mutate(observed = deaths, predicted = pred_test) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "AR: test",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

## Time-series cross-validation

We will now perform time-series cross-validation fitting the model on:

- all the past data up to the forecasting time
- a trailing window of data up to the forecasting time

We set the trailing window to have size = 30,
and we perform 1-step-ahead predictions.

```{r ar-time-series-cv}
n <- nrow(ca)
pred_all_past = pred_trailing <- rep(NA, length = n - t0)
w <- 30 # trailing window size

for (t in (t0+1):n) {
  ar_all_past = lm(deaths ~ lagged_deaths, data = ca,
                    subset = (1:n) <= (t-1))
  ar_trailing = lm(deaths ~ lagged_deaths, data = ca,
                    subset = (1:n) <= (t-1) & (1:n) > (t-1-w))
  pred_all_past[t-t0] = predict(ar_all_past, newdata = data.frame(ca[t, ]))
  pred_trailing[t-t0] = predict(ar_trailing, newdata = data.frame(ca[t, ]))
}

test_ar$pred_cv <- pred_all_past
test_ar$pred_trailing_cv <- pred_trailing
```

We compute the cross-validated error when using all the past data up to the
forecasting time. Since we are refitting the model as new data come in, the
error (under all metrics) is slightly smaller than when using a split-sample
approach, but is still not as small as when we compute it on the training data.

```{r ar-cv-error}
errors_ar <- rbind(errors_ar,
                data.frame("MSE" = MSE(test_ar$deaths, pred_all_past),
                           "MAE"= MAE(test_ar$deaths, pred_all_past),
                           "MAPE" = MAPE(test_ar$deaths, pred_all_past),
                           "MASE" =  MASE(test_ar$deaths, pred_all_past),
                           row.names = "time series CV"))
errors_ar
```

The cross-validated error obtained when using a trailing window is the largest
under all metrics.
This can be explained by the fact that the the relationship between deaths at
two contiguous time points is quite stable over time. Therefore considering a
limited window of data does not improve the fit, and leads instead to a fit that
is slightly too volatile.

```{r ar-cv-trailing-error}
errors_ar <- rbind(errors_ar,
                data.frame("MSE" = MSE(test_ar$deaths, pred_trailing),
                           "MAE"= MAE(test_ar$deaths, pred_trailing),
                           "MAPE" = MAPE(test_ar$deaths, pred_trailing),
                           "MASE" = MASE(test_ar$deaths, pred_trailing),
                           row.names = "time series CV + trailing"))
errors_ar
```

We plot the 1-step-ahead predictions obtained by the model fitted on all past
data and on trailing windows. They are almost always overlapping.

```{r ar-plot-cv-predictions}
test_ar %>%
  mutate(observed = deaths,
         `predicted (CV)` = pred_cv,
         `predicted (trailing + CV)` = pred_trailing_cv) %>%
  pivot_longer(cols = c(observed, `predicted (CV)`, `predicted (trailing + CV)`),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "AR: time-series cross-validation",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


--------------------------------------------------------------------------------

AFTERNOON

```{r epipredict-ar}
ar_all_past <- epi_slide(
  ca,
  ~ arx_forecaster(epi_data = .x,
                   outcome = "deaths",
                   predictors = "deaths",
                   trainer = linear_reg() %>% set_engine("lm"),
                   args_list = arx_args_list(lags = 0L, ahead = 1L)
                   )$predictions,
  .before = Inf,
  .ref_time_values = fc_time_values,
  .new_col_name = "all_past"
) |>
  unpack(all_past, names_sep = "_")

ar_trailing <- epi_slide(
  ca,
  ~ arx_forecaster(epi_data = .x,
                   outcome = "deaths",
                   predictors = "deaths",
                   trainer = linear_reg() %>% set_engine("lm"),
                   args_list = arx_args_list(lags = 0L, ahead = 1L)
                   )$predictions,
  .before = w,
  .ref_time_values = fc_time_values,
  .new_col_name = "trailing"
) |>
  unpack(trailing, names_sep = "_")
```

```{r plot-ar-predictions}
ar_trailing %>%
  left_join(ar_all_past, join_by(time_value, geo_value, cases, deaths)) %>%
  mutate(observed = deaths,
         `predicted (all past)` = all_past_.pred,
         `predicted (trailing)` = trailing_.pred) %>%
  pivot_longer(cols = c(observed, `predicted (all past)`, `predicted (trailing)`),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "Observed and predicted Covid-19 deaths on test set (California)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

```{r ar-check}
# Check that manual implementation and epipredict give same results

if(!all(test_ar$time_value == ar_all_past$all_past_target_date) |
   !all(test_ar$time_value == ar_trailing$trailing_target_date)) {
  print("Error: target dates do not match!")
}

if(!all(test_ar$pred_cv == ar_all_past$all_past_.pred) |
   !all(test_ar$pred_trailing_cv == ar_trailing$trailing_.pred)) {
  print("Error: predictions do not match!")
}

```

--------------------------------------------------------------------------------


# ARX model

To improve our predictive performance, we could put together the two models
considered so far (i.e. linear regression on cases lagged by k = `r k`, and
linear regression on deaths lagged by 1).
This will lead us to the following ARX model

$y_t \approx \beta_0 + \beta_1 y_{t-1} + \beta_2 x_{t-k}$

```{r train/test-arx}
train_arx <- ca %>% filter(time_value <= t0_date)
test_arx <- ca %>% filter(time_value > t0_date)
```

The estimated coefficients for the ARX model are

```{r arx-lm}
arx_fit = lm(deaths ~ lagged_deaths + lagged_cases, data = train_arx)
coef(arx_fit)
```


## Training error

Let's compute the MSE, MAE, MAPE, and MASE on the training set.

```{r arx-training-error}
pred_train <- predict(arx_fit)

train_arx$pred_train <- c(rep(NA, k), pred_train)

errors_arx <- data.frame("MSE" = MSE(train_arx$deaths[-(1:k)], pred_train),
                        "MAE"= MAE(train_arx$deaths[-(1:k)], pred_train),
                        "MAPE" = MAPE(train_arx$deaths[-(1:k)], pred_train),
                        "MASE" = MASE(train_arx$deaths[-(1:k)], pred_train),
                        row.names = "training")
errors_arx
```


```{r arx-plot-train-predictions}
train_arx %>%
  mutate(observed = deaths, predicted = pred_train) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "ARX: training",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


## Split-sample error

Let's compute the MSE, MAE, MAPE, and MASE on the test set.
Here, the test errors are very similar to the training errors.

Notice that the MAPE does not have a finite value because there are some 0s in
the denominator.

```{r arx-test-error}
test_arx$pred_test <- predict(arx_fit, newdata = test_arx)

errors_arx <- rbind(errors_arx,
                  data.frame("MSE" = MSE(test_arx$deaths, test_arx$pred_test),
                             "MAE"= MAE(test_arx$deaths, test_arx$pred_test),
                             "MAPE" = MAPE(test_arx$deaths, test_arx$pred_test),
                             "MASE" = MASE(test_arx$deaths, test_arx$pred_test),
                             row.names = "split-sample"))
errors_arx
```

Let's plot the predictions on the test set.

```{r arx-plot-test-predictions}
test_arx %>%
  mutate(observed = deaths, predicted = pred_test) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "ARX: test",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

## Time-series cross-validation

We will now perform time-series cross-validation fitting the model on:

- all the past data up to the forecasting time
- a trailing window of data up to the forecasting time

We set the trailing window to have size = 30,
and we perform 1-step-ahead predictions.

```{r arx-time-series-cv}
n <- nrow(ca)
pred_all_past = pred_trailing <- rep(NA, length = n - t0)
w <- 30 # trailing window size

for (t in (t0+1):n) {
  arx_all_past = lm(deaths ~ lagged_deaths + lagged_cases, data = ca,
                    subset = (1:n) <= (t-1))
  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca,
                    subset = (1:n) <= (t-1) & (1:n) > (t-1-w))
  pred_all_past[t-t0] = predict(arx_all_past, newdata = data.frame(ca[t, ]))
  pred_trailing[t-t0] = predict(arx_trailing, newdata = data.frame(ca[t, ]))
}

test_arx$pred_cv <- pred_all_past
test_arx$pred_trailing_cv <- pred_trailing
```

We compute the cross-validated error when using all the past data up to the
forecasting time. Since we are refitting the model as new data come in, the
error (under all metrics) is slightly smaller than when using a split-sample
approach, but is still not as small as when we compute it on the training data.

```{r arx-cv-error}
errors_arx <- rbind(errors_arx,
                data.frame("MSE" = MSE(test_arx$deaths, pred_all_past),
                           "MAE" = MAE(test_arx$deaths, pred_all_past),
                           "MAPE" = MAPE(test_arx$deaths, pred_all_past),
                           "MASE" =  MASE(test_arx$deaths, pred_all_past),
                           row.names = "time series CV"))
errors_arx
```

The cross-validated error obtained when using a trailing window is again the
largest under all metrics.

```{r arx-cv-trailing-error}
errors_arx <- rbind(errors_arx,
                data.frame("MSE" = MSE(test_arx$deaths, pred_trailing),
                           "MAE"= MAE(test_arx$deaths, pred_trailing),
                           "MAPE" = MAPE(test_arx$deaths, pred_trailing),
                           "MASE" = MASE(test_arx$deaths, pred_trailing),
                           row.names = "time series CV + trailing"))
errors_arx
```

We plot the 1-step-ahead predictions obtained by the model fitted on all past
data and on trailing windows.

```{r arx-plot-cv-predictions}
test_arx %>%
  mutate(observed = deaths,
         `predicted (CV)` = pred_cv,
         `predicted (trailing + CV)` = pred_trailing_cv) %>%
  pivot_longer(cols = c(observed, `predicted (CV)`, `predicted (trailing + CV)`),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "ARX: time-series cross-validation",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


--------------------------------------------------------------------------------

AFTERNOON

```{r epipredict-arx}
arx_all_past <- epi_slide(
  ca,
  ~ arx_forecaster(epi_data = .x,
                   outcome = "deaths",
                   predictors = c("deaths", "cases"),
                   trainer = linear_reg() %>% set_engine("lm"),
                   args_list = arx_args_list(lags = list(0, k-1),
                                             ahead = 1L)
                   )$predictions,
  .before = Inf,
  .ref_time_values = fc_time_values,
  .new_col_name = "all_past"
) |>
  unpack(all_past, names_sep = "_")

arx_trailing <- epi_slide(
  ca,
  ~ arx_forecaster(epi_data = .x,
                   outcome = "deaths",
                   predictors = c("deaths", "cases"),
                   trainer = linear_reg() %>% set_engine("lm"),
                   args_list = arx_args_list(lags = list(0, k-1),
                                             ahead = 1L)
                   )$predictions,
  .before = (w+k-1),
  .ref_time_values = fc_time_values,
  .new_col_name = "trailing"
) |>
  unpack(trailing, names_sep = "_")


```

```{r plot-arx-predictions}
arx_trailing %>%
  left_join(arx_all_past, join_by(time_value, geo_value, cases, deaths)) %>%
  mutate(observed = deaths,
         `predicted (all past)` = all_past_.pred,
         `predicted (trailing)` = trailing_.pred) %>%
  pivot_longer(cols = c(observed, `predicted (all past)`, `predicted (trailing)`),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  labs(title = "Observed and predicted Covid-19 deaths on test set (California)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


```{r arx-check}
# Check that manual implementation and epipredict give same results

if(!all(test_arx$time_value == arx_all_past$all_past_target_date) |
   !all(test_arx$time_value == arx_trailing$trailing_target_date)) {
  print("Error: target dates do not match!")
}

if(!all(test_arx$pred_cv == arx_all_past$all_past_.pred)) {
  print("Error: all past predictions do not match!")
}

if (!all(test_arx$pred_trailing_cv == arx_trailing$trailing_.pred)) {
  print("Error: trailing predictions do not match!")
}

different <- (test_arx$pred_trailing_cv != arx_trailing$trailing_.pred)

cbind("manual" = test_arx$pred_trailing_cv,
      "epipredict" = arx_trailing$trailing_.pred)[different, ]

```


## Overfitting and Regularization

```{r}
y <- ca$deaths
lags = 1:30

# Build predictor matrix, and run linear regression
X = data.frame(matrix(NA, nrow = length(y), ncol = 2*length(lags)))
for (j in 1:length(lags)) {
  X[, j] = dplyr::lag(ca$deaths, lags[j])
  X[, length(lags) + j] = dplyr::lag(ca$cases, lags[j])
}
colnames(X) = paste('X', 1:ncol(X), sep = '')

head(y); head(X)

y_train <- y[1:t0]
X_train <- X[1:t0, ]
y_test <- y[(t0+1):length(y)]
X_test <- X[(t0+1):length(y), ]

reg = lm(y_train ~ ., data = X_train)
coef(reg)

pred_train <- predict(reg)
pred_test <- predict(reg, newdata = X_test)


ca %>%
  mutate(observed = deaths,
         predicted = c(rep(NA, max(lags)), pred_train, pred_test)) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "ARX with 60 predictors: training and test",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())

```

```{r}
library(glmnet) # Implements LASSO

# We'll need to omit NA values explicitly, as otherwise glmnet will complain
na_obs = 1:max(lags)
X_train = X_train[-na_obs, ]
y_train = y_train[-na_obs]

# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically
ridge = glmnet(X_train, y_train, alpha = 0)
beta_ridge = coef(ridge)
lambda_ridge = ridge$lambda

# Lasso regression: set alpha = 1, and let glmnet() choose a lambda sequence
# itself, automatically
lasso = glmnet(X_train, y_train, alpha = 1)
beta_lasso = coef(lasso)
lambda_lasso = lasso$lambda

dim(beta_lasso)      # One row per coefficient, one column per lambda value
head(beta_lasso)

# Predict values for second half of the time series
yhat_ridge = predict(ridge, newx = as.matrix(X_test))
lambda_ridge = ridge$lambda

yhat_lasso = predict(lasso, newx = as.matrix(X_test))
lambda_lasso = lasso$lambda

# Compute MAE
mae_ridge = colMeans(abs(yhat_ridge - y[(t0+1):n]))
mae_lasso = colMeans(abs(yhat_lasso - y[(t0+1):n]))

# Select index of lambda vector which gives lowest MAE
min_ridge = which.min(mae_ridge)
min_lasso = which.min(mae_lasso)
cbind(beta_ridge[, min_ridge], beta_lasso[, min_lasso])

ggplot() +
  geom_point(aes(1:nrow(beta_ridge), beta_ridge[, min_ridge])) +
  geom_point(aes(1:nrow(beta_lasso), beta_lasso[, min_lasso]), col = 'red') +
  xlab('Regressor') +
  ylab('Estimated coefficient')

min(mae_ridge); min(mae_lasso)
```


```{r}
pred_train <- predict(lasso, newx = as.matrix(X_train))[, min_lasso]
pred_test <- yhat_lasso[, min_lasso]

ca %>%
  mutate(observed = deaths,
         predicted = c(rep(NA, max(lags)), pred_train, pred_test)) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "ARX + LASSO with 60 predictors: training and test",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

```{r}
pred_train <- predict(ridge, newx = as.matrix(X_train))[, min_ridge]
pred_test <- yhat_ridge[, min_ridge]

ca %>%
  mutate(observed = deaths,
         predicted = c(rep(NA, max(lags)), pred_train, pred_test)) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "ARX + Ridge with 60 predictors: training and test",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


```{r}
yhat_ridge = matrix(NA, ncol = length(lambda_ridge), nrow = n-t0)
yhat_lasso = matrix(NA, ncol = length(lambda_lasso), nrow = n-t0)

for (t in (t0+1):n) {
  inds = t-1-w < 1:n & 1:n <= t-1
  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)
  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)
  yhat_ridge[t-t0, ] = predict(ridge_trail, newx = as.matrix(X[t, ]))
  yhat_lasso[t-t0, ] = predict(lasso_trail, newx = as.matrix(X[t, ]))
}

mae_ridge = colMeans(abs(yhat_ridge - y[(t0+1):n]))
mae_lasso = colMeans(abs(yhat_lasso - y[(t0+1):n]))

min_ridge = which.min(mae_ridge)
min_lasso = which.min(mae_lasso)

min(mae_ridge); min(mae_lasso)
```

```{r}
pred_cv_ridge <- yhat_ridge[, min_ridge]
pred_cv_lasso <- yhat_lasso[, min_lasso]

test %>%
  mutate(observed = deaths,
         ridge = pred_cv_ridge,
         lasso = pred_cv_lasso) %>%
  pivot_longer(cols = c(observed, ridge, lasso), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line() +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "ARX + Ridge/LASSO with 60 predictors: time-series CV",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


## Prediction Intervals

So far we focused on point predictions, i.e. we provided one "best" value as our
guess for the number of deaths. We will now introduce 95% predictions intervals:
each forecast will be accompanied by an interval (i.e. a range of values) that
we expect to cover the true number of deaths about 95% of the times.

To get prediction intervals from the previous code, we only need to tweak our
call to `predict` by adding as an input: `interval = "prediction", level = 0.95`.
The output from `predict` will then be a matrix with first column a point
estimate, second column the lower limit of the interval, and third column the
upper limit of the interval.

Next, we plot the point predictions on the training and test set together with
the prediction intervals (shadowed bands).

```{r arx-intervals-test}
pred_test_ci <- predict(arx_fit, newdata = test_arx,
                        interval = "prediction", level = 0.95)

head(pred_test_ci)

test_arx %>%
  mutate(observed = deaths,
         predicted = pred_test_ci[, 1],
         lower = pred_test_ci[, 2],
         upper = pred_test_ci[, 3]) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4,
              fill = hue_pal()(2)[2]) +
  geom_line(aes(col = Deaths)) +
  labs(title = "ARX: point predictions and intervals on test set",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

We can also provide prediction intervals for the cross-validated approach.

Notice that the width of the prediction intervals varies substantially for the
trailing window method.

```{r arx-intervals-time-series-cv}
n <- nrow(ca)
pred_all_past = pred_trailing <- matrix(NA, nrow = n - t0, ncol = 3)
colnames(pred_all_past) = colnames(pred_trailing) <- c('prediction',
                                                       'lower', 'upper')
w <- 30 # trailing window size

for (t in (t0+1):n) {
  arx_all_past = lm(deaths ~ lagged_deaths + lagged_cases, data = ca,
                    subset = (1:n) <= (t-1))
  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca,
                    subset = (1:n) <= (t-1) & (1:n) > (t-1-w))
  pred_all_past[t-t0, ] = predict(arx_all_past, newdata = data.frame(ca[t, ]),
                                interval = "prediction", level = 0.95)
  pred_trailing[t-t0, ] = predict(arx_trailing, newdata = data.frame(ca[t, ]),
                                interval = "prediction", level = 0.95)
}

lm_pred_all_past <- cbind(test_arx %>% select(time_value, deaths),
                           pred_all_past)

lm_pred_trailing <- cbind(test_arx %>% select(time_value, deaths),
                           pred_trailing)

```

```{r plot arx-intervals-cv}
lm_pred_all_past %>%
  mutate(observed = deaths,
         `predicted (CV)` = prediction) %>%
  pivot_longer(cols = c(observed, `predicted (CV)`),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4,
              fill = hue_pal()(2)[2]) +
  geom_line(aes(col = Deaths)) +
  labs(title = "ARX: point predictions and intervals (time-series CV)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())

lm_pred_trailing %>%
  mutate(observed = deaths,
         `predicted (CV + trailing)` = prediction) %>%
  pivot_longer(cols = c(observed, `predicted (CV + trailing)`),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4,
              fill = hue_pal()(2)[2]) +
  geom_line(aes(col = Deaths)) +
  labs(title = "ARX: point predictions and intervals (time-series CV)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```



# Quantile Regression

```{r q-reg-library}
#install.packages("quantreg")
library(quantreg)
```

```{r train/test-q-reg}
train_rq <- ca %>% filter(time_value <= t0_date)
test_rq <- ca %>% filter(time_value > t0_date)
```


```{r q-reg}
quantile_levels <- c(0.025, 0.5, 0.975)
q_reg = rq(deaths ~ lagged_deaths + lagged_cases, data = train_rq,
           tau = quantile_levels)
coef(q_reg)
```


## Train/test predictions

Let's plot the predictions (point estimates and 95% confidence intervals)
for the training and test sets.

```{r q-reg-training}
pred_train <- rbind(matrix(NA, nrow = k, ncol = 3),
                    predict(q_reg))
pred_test <- predict(q_reg, newdata = test_rq)

preds <- rbind(pred_train, pred_test)

ca %>%
  mutate(observed = deaths,
         predicted = preds[, 2],
         lower = preds[, 1],
         upper = preds[, 3]) %>%
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4,
              fill = hue_pal()(2)[2]) +
  geom_line(aes(col = Deaths)) +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "Quantile Regression: point predictions and intervals (train/test)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```


## Time-series cross-validation

We will now perform time-series cross-validation fitting the model on:

- all the past data up to the forecasting time
- a trailing window of data up to the forecasting time

We set the trailing window to have size = 30,
and we perform 1-step-ahead predictions.

```{r q-reg-time-series-cv}
n <- nrow(ca)
pred_all_past = pred_trailing <- matrix(NA, nrow = n - t0, ncol = 3)
colnames(pred_all_past) = colnames(pred_trailing) <- c('lower', 'median',
                                                       'upper')

w <- 30 # trailing window size

for (t in (t0+1):n) {
  rq_all_past = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantile_levels,
                   data = ca, subset = (1:n) <= (t-1))
  rq_trailing = rq(deaths ~ lagged_deaths + lagged_cases, tau = quantile_levels,
                   data = ca, subset = (1:n) <= (t-1) & (1:n) > (t-1-w))
  pred_all_past[t-t0, ] = predict(rq_all_past, newdata = data.frame(ca[t, ]))
  pred_trailing[t-t0, ] = predict(rq_trailing, newdata = data.frame(ca[t, ]))
}

rq_pred_all_past <- cbind(test_rq %>% select(time_value, deaths),
                           pred_all_past)

rq_pred_trailing <- cbind(test_rq %>% select(time_value, deaths),
                           pred_trailing)

```

We plot the 1-step-ahead predictions obtained by the model fitted on all past
data and on trailing windows.

```{r q-reg-plot-cv-predictions}
rq_pred_all_past %>%
  mutate(observed = deaths,
         `predicted (CV)` = median) %>%
  pivot_longer(cols = c(`predicted (CV)`, observed), names_to = 'Deaths') %>%
  ggplot(aes(time_value, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4,
              fill = hue_pal()(2)[2]) +
  geom_line(aes(col = Deaths)) +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "Quantile Regression: point predictions and intervals (time-series CV)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())

rq_pred_trailing %>%
  mutate(observed = deaths,
         `predicted (trailing + CV)` = median) %>%
  pivot_longer(cols = c(`predicted (trailing + CV)`, observed),
               names_to = 'Deaths') %>%
  ggplot(aes(time_value, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4,
              fill = hue_pal()(2)[2]) +
  geom_line(aes(col = Deaths)) +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "Quantile Regression: point predictions and intervals (time-series CV)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

# Evaluation for Prediction Intervals

Are the intervals obtained actually covering the observed death rate about 95%
of the times?
How do we compare the performance of different prediction intervals?

We will first look into actual coverage of the prediction intervals we obtained,
and then consider a metric called "Weighted Interval Score" (WIS).

The coverage of ARX (fittem via `lm`) on all past data is around the expected
coverage of 95%:

```{r lm-coverage-all-past}
lm_pred_all_past %>%
  summarise(coverage = mean(deaths >= lower & deaths <= upper,
                            na.rm = TRUE))
```

The actual coverage for the same model trained on a trailing window is a bit
lower:

```{r lm-coverage-trailing}
lm_pred_trailing %>%
  summarise(coverage = mean(deaths >= lower & deaths <= upper,
                            na.rm = TRUE))
```

The coverage of the model fitted by quantile regression on all past data is
quite low:

```{r rq-coverage-all-past}
rq_pred_all_past %>%
  summarise(coverage = mean(deaths >= lower & deaths <= upper,
                            na.rm = TRUE))
```

The actual coverage for the same model trained on a trailing window is even
lower:

```{r rq-coverage-trailing}
rq_pred_trailing %>%
  summarise(coverage = mean(deaths >= lower & deaths <= upper,
                            na.rm = TRUE))
```

We will now evaluate the forecast intervals using a different measure: the
Weighted Interval Score (WIS). The following is a function to compute the WIS,
given observed data (`truth`), and corresponding `estimates` for different
quantiles (`quantile_levels`).

```{r wis-function}
WIS <- function(truth, estimates, quantile_levels) {
  2 * mean(pmax(
    quantile_levels * (truth - estimates),
    (1 - quantile_levels) * (estimates - truth),
    na.rm = TRUE
  ))
}
```

Below is the mean WIS for the ARX model fitted via `lm` on all past data.

```{r wis-lm-all-past}
lm_pred_all_past %>%
  rowwise() %>%
  mutate(wis = WIS(deaths,
                   c(lower, prediction, upper),
                   quantile_levels)) %>%
  ungroup() %>%
  summarise(mean_wis = mean(wis, na.rm = T))
```

The mean WIS for the same model fitted on a trailing window is:

```{r wis-lm-trailing}
lm_pred_trailing %>%
  rowwise() %>%
  mutate(wis = WIS(deaths,
                   c(lower, prediction, upper),
                   quantile_levels)) %>%
  ungroup() %>%
  summarise(mean_wis = mean(wis, na.rm = T))
```


Below is the mean WIS for the ARX model fitted via `rq` on all past data.

```{r wis-lm-all-past}
rq_pred_all_past %>%
  rowwise() %>%
  mutate(wis = WIS(deaths,
                   c(lower, median, upper),
                   quantile_levels)) %>%
  ungroup() %>%
  summarise(mean_wis = mean(wis, na.rm = T))
```

The mean WIS for the same model fitted on a trailing window is:

```{r wis-lm-trailing}
rq_pred_trailing %>%
  rowwise() %>%
  mutate(wis = WIS(deaths,
                   c(lower, median, upper),
                   quantile_levels)) %>%
  ungroup() %>%
  summarise(mean_wis = mean(wis, na.rm = T))
```



# Forecasting with Versioned Data

```{r download-versioned-data}
states <- "*"

cases_archive <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_incidence_prop",
  time_type = "day",
  geo_type = "state",
  time_values = epirange(20200401, 20220101),
  geo_values = states,
  issues = epirange(20200401, 20220101)) %>%
  select(geo_value, time_value, version = issue, case_rate = value) %>%
  arrange(geo_value, time_value) %>%
  as_epi_archive(compactify = FALSE)

deaths_archive <- pub_covidcast(
  source = "jhu-csse",
  signals = "deaths_incidence_prop",
  time_type = "day",
  geo_type = "state",
  time_values = epirange(20200401, 20220101),
  geo_values = states,
  issues = epirange(20200401, 20220101)) %>%
  select(geo_value, time_value, version = issue, death_rate = value) %>%
  arrange(geo_value, time_value) %>%
  as_epi_archive(compactify = FALSE)

data_archive <- epix_merge(cases_archive, deaths_archive, sync = "locf")

data_archive
```

```{r weekly-avg}
#fc_time_values <- seq(
#  from = as.Date("2020-09-01"),
#  to = as.Date("2021-12-31"),
#  by = "1 month"
#)

fc_time_values <- seq(
  from = t0_date,
  to = as.Date("2021-12-31"),
  by = "1 day"
)

data_archive <- data_archive %>%
  epix_slide(
    .before = Inf,
    .versions = fc_time_values,
    function(x, gk, rtv) {
      x %>%
        epi_slide_mean(case_rate, .window_size = 7L, .suffix = "_7d_av") %>%
        epi_slide_mean(death_rate, .window_size = 7L, .suffix = "_7d_av")
    }
  ) %>%
  rename(version = time_value) %>%
  rename(
    time_value = slide_value_time_value,
    geo_value = slide_value_geo_value,
    cases = slide_value_case_rate_7d_av,
    deaths = slide_value_death_rate_7d_av
  ) %>%
  select(version, time_value, geo_value, cases, deaths) %>%
  as_epi_archive(compactify = TRUE)

#saveRDS(x$DT, file = "case_death_rate_archive.rds")

ca_archive <- data_archive$DT %>%
  #filter(geo_value == "ca") %>%
  as_epi_archive()

ca_archive
```

```{r versioned-quantile-reg}
pred_all_past = pred_trailing <- matrix(NA, ncol = 4, nrow = 0)

w <- 30 # trailing window size

for (fc_date in fc_time_values) {
  data <- epix_as_of(ca_archive, as.Date(fc_date))
  data$lagged_deaths <- dplyr::lag(data$deaths, 1)
  data$lagged_cases <- dplyr::lag(data$cases, k)

  rq_all_past <- rq(deaths ~ lagged_deaths + lagged_cases,
                    tau = c(.025, .5, .975), data = data)
  rq_trailing <- rq(deaths ~ lagged_deaths + lagged_cases,
                    tau = c(.025, .5, .975),
                    data = data %>%
                      filter(time_value > (max(time_value) - w)))

  new <- data.frame(geo_value = "ca",
                    time_value = max(data$time_value) + 1,
                    cases = NA, deaths = NA,
                    lagged_deaths = tail(data$deaths, 1),
                    lagged_cases = (data %>%
                                      filter(time_value ==
                                               (max(time_value) - k + 1)))$cases)

  pred_all_past <- rbind(pred_all_past,
                         cbind('target_date' = new$time_value,
                               predict(rq_all_past, newdata = new)))
  pred_trailing <- rbind(pred_trailing,
                         cbind('target_date' = new$time_value,
                               predict(rq_trailing, newdata = new)))
}

pred_all_past <- as.data.frame(pred_all_past,
                               row.names = 1:nrow(pred_all_past)) %>%
  mutate(target_date = as.Date(target_date)) %>%
  rename(median = `tau= 0.500`,
         lower = `tau= 0.025`,
         upper = `tau= 0.975`) %>%
  full_join(ca %>%
              select(time_value, deaths),
            join_by(target_date == time_value)) %>%
  arrange(target_date)


pred_trailing <- as.data.frame(pred_trailing,
                               row.names = 1:nrow(pred_trailing)) %>%
  mutate(target_date = as.Date(target_date)) %>%
  rename(median = `tau= 0.500`,
         lower = `tau= 0.025`,
         upper = `tau= 0.975`) %>%
  full_join(ca %>%
              select(time_value, deaths),
            join_by(target_date == time_value)) %>%
  arrange(target_date)

```


```{r plot-versioned-cv}
pred_all_past %>%
  mutate(observed = deaths,
         `predicted (CV)` = median) %>%
  pivot_longer(cols = c(`predicted (CV)`, observed), names_to = 'Deaths') %>%
  ggplot(aes(target_date, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4) +
  geom_line(aes(col = Deaths)) +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "Versioned Quantile Regression (time-series CV)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

```{r plot-versioned-cv-trailing}
pred_trailing %>%
  mutate(observed = deaths,
         `predicted (CV + trailing)` = median) %>%
  pivot_longer(cols = c(`predicted (CV + trailing)`,
                        observed), names_to = 'Deaths') %>%
  ggplot(aes(target_date, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .4) +
  geom_line(aes(col = Deaths)) +
  geom_vline(xintercept = t0_date, lty = 2) +
  labs(title = "Versioned Quantile Regression (time-series CV + trailing)",
       x = "", y = "Covid-19 deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

Are the intervals obtained actually covering the observed death rate about 95%
of the times?

```{r quantile-reg-coverage-all-past}
pred_all_past %>%
  summarise(coverage = mean(deaths >= lower & deaths <= upper,
                            na.rm = TRUE))
```

The actual coverage for the model trained on all past data is lower than 95%.
If we look at the model trained on a trailing window, coverage is even lower.

```{r quantile-reg-coverage-trailing}
pred_trailing %>%
  summarise(coverage = mean(deaths >= lower & deaths <= upper,
                            na.rm = TRUE))
```

Below is the mean WIS for the model fitted on all past data.

```{r wis-all-past}
pred_all_past %>%
  rowwise() %>%
  mutate(wis = WIS(deaths,
                   c(lower, median, upper),
                   c(.025, .5, .975))) %>%
  ungroup() %>%
  summarise(mean_wis = mean(wis, na.rm = T))
```

The mean WIS for the model fitted on a trailing window is:

```{r wis-trailing}
pred_trailing %>%
  rowwise() %>%
  mutate(wis = WIS(deaths,
                   c(lower, median, upper),
                   c(.025, .5, .975))) %>%
  ungroup() %>%
  summarise(mean_wis = mean(wis, na.rm = T))
```

--------------------------------------------------------------------------------

```{r}
aheads <- c(7, 14, 21)

forecaster <- function(x) {
  map(aheads, function(ahead) {
    arx_forecaster(
      epi_data = x,
      outcome = "death_rate_7d_av",
      predictors = c("death_rate_7d_av", "case_rate_7d_av"),
      trainer = quantile_reg(),
      args_list = arx_args_list(lags = c(0, 7, 14, 21), ahead = ahead)
    )$predictions
  }) %>%
    bind_rows()
}

arx_preds <- data %>%
  epix_slide(~ forecaster(.x),
    .before = 120, .versions = fc_time_values
  ) %>%
  mutate(engine_type = quantile_reg()$engine) %>%
  mutate(ahead_val = target_date - forecast_date)

x_latest <- epix_as_of(data, data$versions_end)
```


```{r}
states_to_show <- c("ca", "ny", "mi", "az")

fc_states <- arx_preds %>%
  filter(geo_value %in% states_to_show) %>%
  pivot_quantiles_wider(.pred_distn)

x_latest_states <- x_latest %>% filter(geo_value %in% states_to_show)

ggplot(fc_states, aes(target_date, group = time_value)) +
  geom_ribbon(aes(ymin = `0.05`, ymax = `0.95`, fill = geo_value), alpha = 0.4) +
  geom_line(
    data = x_latest_states, aes(x = time_value, y = death_rate_7d_av),
    inherit.aes = FALSE, color = "gray50"
  ) +
  geom_line(aes(y = .pred, color = geo_value)) +
  geom_point(aes(y = .pred, color = geo_value), size = 0.5) +
  geom_vline(aes(xintercept = time_value), linetype = 2, alpha = 0.5) +
  facet_wrap(~geo_value, scales = "free_y", ncol = 1L) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1") +
  labs(x = "Date", y = "7 day average COVID-19 death rates") +
  theme(legend.position = "none")
```


--------------------------------------------------------------------------------

AFTERNOON

# LASSO

```{r lasso}
ar_lasso <- arx_forecaster(epi_data = train %>% as_epi_df(),
                           outcome = "deaths",
                           predictors = "deaths",
                           trainer = linear_reg(penalty = double(1),
                                                mixture = double(1)) %>%
                             set_engine("glmnet") %>%
                             #set_engine("spark") %>%
                             translate(),
                           args_list = arx_args_list(lags = c(0L, 7L, 14L),
                                                     ahead = 1L))

ar_lasso_fit <- extract_fit_parsnip(ar_lasso$epi_workflow)
#ar_lasso_fit
```


