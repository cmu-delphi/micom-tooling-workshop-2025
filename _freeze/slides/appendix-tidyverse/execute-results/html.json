{
  "hash": "f41efab672e7b6050943376f817a81b5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntalk-title: \"Background on `{tidyverse}`\"\ntalk-short-title: \"Background on `{tidyverse}`\"\ntalk-subtitle: \"MICOM Tooling Workshop 2025\"\ntalk-date: \"12 August 2025\"\nformat: revealjs\n---\n\n---\n---\n\n\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n\n\n\n\n\n\n\n::: flex\n::: w-20\n\n:::\n::: w-80\n## {{< meta talk-title >}} {background-image=\"gfx/cover-art-1.svg\" background-position=\"bottom\"}\n\n### {{< meta talk-subtitle >}}\n\n<br>\n\n#### {{< meta author >}} \n[Adapted from slides by Alice Cima, Rachel Lobay, Daniel McDonald, Ryan Tibshirani, with huge thanks to Logan Brooks, Xueda Shen, and Dmitry Shemetov]{.fstyle}\n\n\n{{< meta talk-date >}}\n\n\n:::\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n# Essentials of `{dplyr}` and `{tidyr}`\n\n## Down with spreadsheets for data manipulation\n\n* Spreadsheets make it difficult to rerun analyses consistently.\n* Using R (and `{dplyr}`) allows for:\n  * Reproducibility\n  * Ease of modification\n* [**Recommendation**]{.primary}: Avoid manual edits; instead, use code for transformations.\n* Let's see what we mean by this...\n\n## Introduction to `dplyr`\n\n* `dplyr` is a powerful package in R for data manipulation.\n* It is part of the `tidyverse`, which includes a collection of packages designed to work together... Here's some of it's greatest hits:\n\n<div style=\"text-align: center;\">\n![](gfx/tidyverse_packages.png){style=\"width: 30%; display: block; margin-left: auto; margin-right: auto;\"}\n<br>\n<small>[Source](https://laddem.github.io/courses/tidyverse/)</small>\n</div>\n\n## Introduction to `dplyr`\n\n![](gfx/dplyr.png){style=\"height: 450px\"}\n\nTo load `dplyr` you may simply load the `tidyverse` package:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)  # Load tidyverse, which includes dplyr & tidyr\n```\n:::\n\n\n\n## Introduction to `dplyr`\nOur focus will be on basic operations like selecting and filtering data.\n\n![](gfx/dplyr_and_fun.png){style=\"width: 70%;\"}\n<div style=\"text-align: center;\">\n<small>[Source](https://towardsdatascience.com/data-manipulation-in-r-with-dplyr-3095e0867f75)</small>\n</div>\n\n\n## Downloading JHU CSSE COVID-19 case data\n\n* Let's start with something familiar... Here's a task for you:\n* Use `pub_covidcast()` to download [**JHU CSSE COVID-19 confirmed case data**]{.primary} (`confirmed_incidence_num`) for CA, NC, and NY from March 1, 2022 to March 31, 2022 as of January 1, 2024.\n* Try this for yourself. Then click the dropdown on the next slide to check your work...\n\n## Downloading JHU CSSE COVID-19 case data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(epidatr)\n\ncases_df <- pub_covidcast(\n  source = \"jhu-csse\",\n  signals = \"confirmed_incidence_num\",\n  geo_type = \"state\",\n  time_type = \"day\",\n  geo_values = \"ca,nc,ny\",\n  time_values = epirange(20220301, 20220331),\n  as_of = as.Date(\"2024-01-01\")\n)\n```\n:::\n\n\n\nNow we only really need a few columns here...\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncases_df <- cases_df |>\n  select(geo_value, time_value, raw_cases = value) # We'll talk more about this soon :)\n```\n:::\n\n\n\n## Ways to inspect the dataset\n\nUse `head()` to view the first six row of the data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(cases_df)  # First 6 rows\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n```\n\n\n:::\n:::\n\n\n\nand tail to view the last six\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-30      3785\n2 nc        2022-03-30      1067\n3 ny        2022-03-30      3127\n4 ca        2022-03-31      4533\n5 nc        2022-03-31      1075\n6 ny        2022-03-31      4763\n```\n\n\n:::\n:::\n\n\n\n## Ways to inspect the dataset\nNow, for our first foray into the `tidyverse`...\n\nUse `glimpse()` to get a compact overview of the dataset.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(cases_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 93\nColumns: 3\n$ geo_value  <chr> \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\", \"nc\", \"ny\", \"ca\",…\n$ time_value <date> 2022-03-01, 2022-03-01, 2022-03-01, 2022-03-02, 2022-03-02…\n$ raw_cases  <dbl> 4310, 1231, 1487, 7044, 2243, 1889, 7509, 2377, 2390, 3586,…\n```\n\n\n:::\n:::\n\n\n\n## Creating tibbles\n\n* [**Tibbles**]{.primary}: Modern data frames with enhanced features.\n* Rows represent [**observations**]{.primary} (or cases).\n* Columns represent [**variables**]{.primary} (or features).\n* You can create tibbles manually using the `tibble()` function.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntibble(x = letters, y = 1:26)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 26 × 2\n   x         y\n   <chr> <int>\n 1 a         1\n 2 b         2\n 3 c         3\n 4 d         4\n 5 e         5\n 6 f         6\n 7 g         7\n 8 h         8\n 9 i         9\n10 j        10\n# ℹ 16 more rows\n```\n\n\n:::\n:::\n\n\n\n## Selecting columns with `select()`\n\nThe `select()` function is used to pick specific columns from your dataset.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nselect(cases_df, geo_value, time_value)  # Select the 'geo_value' and 'time_value' columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 93 × 2\n   geo_value time_value\n   <chr>     <date>    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows\n```\n\n\n:::\n:::\n\n\n\n## Selecting columns with `select()`\n\nYou can exclude columns by prefixing the column names with a minus sign `-`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nselect(cases_df, -raw_cases)  # Exclude the 'raw_cases' column from the dataset\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 93 × 2\n   geo_value time_value\n   <chr>     <date>    \n 1 ca        2022-03-01\n 2 nc        2022-03-01\n 3 ny        2022-03-01\n 4 ca        2022-03-02\n 5 nc        2022-03-02\n 6 ny        2022-03-02\n 7 ca        2022-03-03\n 8 nc        2022-03-03\n 9 ny        2022-03-03\n10 ca        2022-03-04\n# ℹ 83 more rows\n```\n\n\n:::\n:::\n\n\n\n## Extracting columns with `pull()`\n\n* `pull()`: Extract a column as a vector.\n* Let's try this with the `cases` column...\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npull(cases_df, raw_cases)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 4310 1231 1487 7044 2243 1889 7509 2377 2390 3586 2646  350 1438    0 3372\n[16] 6465    0 2343 6690 4230 1033 3424  894 1025 4591 1833 1691 5359 1783 1747\n[31] 2713 1849 2229 1623    0 1396 5151    0 2202 4826 3130  982 1831  649 3128\n[46] 3706    0 2039 6143 2742 2356 4204 1740 2052 3256    0 2188 4659    0 2667\n[61] 5499 2508 1177 3004  819 1603 3943 1602  551 3550 1288 6596 1960 1224 3542\n[76] 1035    0    0 3384    0 5908 2811 2291 2286 1846  624 2394 3785 1067 3127\n[91] 4533 1075 4763\n```\n\n\n:::\n:::\n\n\n\n## Subsetting rows with `filter()`\n\n<div style=\"text-align: center;\">\n![](gfx/dplyr_filter.png){style=\"width: 65%; display: block; margin-left: auto; margin-right: auto;\"}\n<br>\n<small>[Artwork by @allison_horst](https://x.com/allison_horst)</small>\n</div>\n\n## Subsetting rows with `filter()`\n\n* The `filter()` function allows you to subset rows that meet specific conditions.\n* Conditions regard column values, such as filtering for only NC or cases higher than some threshold.\n* This enables you to narrow down your dataset to focus on relevant data.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfilter(cases_df, geo_value == \"nc\", raw_cases > 500)  # Filter for NC with raw daily cases > 500\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 22 × 3\n   geo_value time_value raw_cases\n   <chr>     <date>         <dbl>\n 1 nc        2022-03-01      1231\n 2 nc        2022-03-02      2243\n 3 nc        2022-03-03      2377\n 4 nc        2022-03-04      2646\n 5 nc        2022-03-07      4230\n 6 nc        2022-03-08       894\n 7 nc        2022-03-09      1833\n 8 nc        2022-03-10      1783\n 9 nc        2022-03-11      1849\n10 nc        2022-03-14      3130\n# ℹ 12 more rows\n```\n\n\n:::\n:::\n\n\n\n## Combining `select()` and `filter()` functions\n\n* You can further combine `select()` and `filter()` to further refine the dataset.\n* Use `select()` to choose columns and `filter()` to narrow down rows.\n* This helps in extracting the exact data needed for analysis.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nselect(filter(cases_df, geo_value == \"nc\", raw_cases > 1000), time_value, raw_cases) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  time_value raw_cases\n  <date>         <dbl>\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833\n```\n\n\n:::\n:::\n\n\n\n## Using the pipe operator `|>`\n\n* The pipe operator (`|>`) makes code more readable by chaining multiple operations together.\n* The output of one function is automatically passed to the next function.\n* This allows you to perform multiple steps (e.g., `filter()` followed by `select()`) in a clear and concise manner.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# This code reads more like poetry!\ncases_df |>\n  filter(geo_value == \"nc\", raw_cases > 1000) |>\n  select(time_value, raw_cases) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  time_value raw_cases\n  <date>         <dbl>\n1 2022-03-01      1231\n2 2022-03-02      2243\n3 2022-03-03      2377\n4 2022-03-04      2646\n5 2022-03-07      4230\n6 2022-03-09      1833\n```\n\n\n:::\n:::\n\n\n\n## Key practices in `dplyr`\n\n* Use [**tibbles**]{.primary} for easier data handling.\n* Use `select()` and `filter()` for data manipulation.\n* Use `pull()` to extract columns as vectors.\n* Use `head()`, `tail()`, and `glimpse()` for quick data inspection.\n* Chain functions with `|>` for cleaner code.\n\n## Grouping data with `group_by()`\n\n* Use `group_by()` to group data by one or more columns.\n* Allows performing operations on specific groups of data.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncases_df |>\n  group_by(geo_value) |>\n  filter(raw_cases == max(raw_cases, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n# Groups:   geo_value [3]\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-03      7509\n2 nc        2022-03-07      4230\n3 ny        2022-03-24      6596\n```\n\n\n:::\n:::\n\n\n\n## Creating new columns with `mutate()`\n\n<div style=\"text-align: center;\">\n![](gfx/dplyr_mutate.jpg){style=\"width: 45%; display: block; margin-left: auto; margin-right: auto;\"}\n<br>\n<small>[Artwork by @allison_horst](https://x.com/allison_horst)</small>\n</div>\n\n## Creating new columns with `mutate()`\n\n* `mutate()` is used to create new columns.\n* Perform calculations using existing columns and assign to new columns.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nny_subset = cases_df |>\n  filter(geo_value == \"ny\")\n\nny_subset |>\n  mutate(cumulative_cases = cumsum(raw_cases)) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  geo_value time_value raw_cases cumulative_cases\n  <chr>     <date>         <dbl>            <dbl>\n1 ny        2022-03-01      1487             1487\n2 ny        2022-03-02      1889             3376\n3 ny        2022-03-03      2390             5766\n4 ny        2022-03-04       350             6116\n5 ny        2022-03-05      3372             9488\n6 ny        2022-03-06      2343            11831\n```\n\n\n:::\n:::\n\n\n\n## Creating new columns with `mutate()`\n\n* `mutate()` can create multiple new columns in one step.\n* Logical comparisons (e.g., `over_5000 = raw_cases > 5000`) can be used within `mutate()`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nny_subset |>\n  mutate(over_5000 = raw_cases > 5000,\n         cumulative_cases = cumsum(raw_cases)) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  geo_value time_value raw_cases over_5000 cumulative_cases\n  <chr>     <date>         <dbl> <lgl>                <dbl>\n1 ny        2022-03-01      1487 FALSE                 1487\n2 ny        2022-03-02      1889 FALSE                 3376\n3 ny        2022-03-03      2390 FALSE                 5766\n4 ny        2022-03-04       350 FALSE                 6116\n5 ny        2022-03-05      3372 FALSE                 9488\n6 ny        2022-03-06      2343 FALSE                11831\n```\n\n\n:::\n:::\n\n\n\n## Combining `group_by()` and `mutate()`\n\n* First, group data using `group_by()`.\n* Then, use `mutate` to perform the calculations for each group.\n* Finally, use `arrange` to display the output by `geo_value`.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncases_df |>\n  group_by(geo_value) |>\n  mutate(cumulative_cases = cumsum(raw_cases)) |>\n  arrange(geo_value) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n# Groups:   geo_value [1]\n  geo_value time_value raw_cases cumulative_cases\n  <chr>     <date>         <dbl>            <dbl>\n1 ca        2022-03-01      4310             4310\n2 ca        2022-03-02      7044            11354\n3 ca        2022-03-03      7509            18863\n4 ca        2022-03-04      3586            22449\n5 ca        2022-03-05      1438            23887\n6 ca        2022-03-06      6465            30352\n```\n\n\n:::\n:::\n\n\n\n## Conditional calculations with `if_else()`\n* `if_else()` allows conditional logic within `mutate()`.\n* Perform different operations depending on conditions, like \"high\" or \"low.\"\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nt <- 5000\n\ncases_df |>\n  mutate(high_low_cases = if_else(raw_cases > t, \"high\", \"low\")) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  geo_value time_value raw_cases high_low_cases\n  <chr>     <date>         <dbl> <chr>         \n1 ca        2022-03-01      4310 low           \n2 nc        2022-03-01      1231 low           \n3 ny        2022-03-01      1487 low           \n4 ca        2022-03-02      7044 high          \n5 nc        2022-03-02      2243 low           \n6 ny        2022-03-02      1889 low           \n```\n\n\n:::\n:::\n\n\n\n## Summarizing data with `summarise()`\n* `summarise()` reduces data to summary statistics (e.g., mean, median).\n* Typically used after `group_by()` to summarize each group.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncases_df |>\n  group_by(geo_value) |>\n  summarise(median_cases = median(raw_cases))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  geo_value median_cases\n  <chr>            <dbl>\n1 ca                3785\n2 nc                1224\n3 ny                2188\n```\n\n\n:::\n:::\n\n\n\n## Using `count()` to aggregate data\n`count()` is a shortcut for grouping and summarizing the data.\n\nFor example, if we want to get the total number of complete rows for each state, then\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncases_count <- cases_df |>\n  drop_na() |> # Removes rows where any value is missing (from tidyr)\n  group_by(geo_value) |>\n  summarize(count = n())\n```\n:::\n\n\n<br>\nis equivalent to\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncases_count <- cases_df |>\n  drop_na() |>\n  count(geo_value)\n\ncases_count # Let's see what the counts are.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  geo_value     n\n  <chr>     <int>\n1 ca           31\n2 nc           31\n3 ny           31\n```\n\n\n:::\n:::\n\n\n\n## Key practices in `dplyr`: Round 2\n\n* Use `group_by()` to group data by one or more variables before applying functions.\n* Use `mutate` to create new columns or modify existing ones by applying functions to existing data.\n* Use `summarise` to reduce data to summary statistics (e.g., mean, median).\n* `count()` is a convenient shortcut for counting rows by group without needing `group_by()` and `summarise()`.\n\n## Tidy data and Tolstoy\n\n> \"Happy families are all alike; every unhappy family is unhappy in its own way.\" — Leo Tolstoy\n\n* [**Tidy datasets**]{.primary} are like happy families: consistent, standardized, and easy to work with.\n* [**Messy datasets**]{.primary} are like unhappy families: each one messy in its own unique way.\nIn this section:\n* We'll define what makes data *tidy* and how to transform between the tidy and messy formats.\n\n## Tidy data and Tolstoy\n\n![](gfx/tidy_messy_data.jpg){style=\"width: 60%;\"}\n\n<small>[Artwork by @allison_horst](https://x.com/allison_horst)</small>\n\n\n## What is tidy data?\n\n* Tidy data follows a consistent structure: [**each row represents one observation, and each column represents one variable.**]{.primary}\n* `cases_df` is one classic example of tidy data.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n4 ca        2022-03-02      7044\n5 nc        2022-03-02      2243\n6 ny        2022-03-02      1889\n```\n\n\n:::\n:::\n\n\n\n* To convert between tidy and messy data, we can use the `tidyr` package in the tidyverse.\n\n## `pivot_wider()` and  `pivot_longer()`\n<div style=\"text-align: center;\">\n![](gfx/pivot_wider_longer.jpg){style=\"width: 40%; display: block; margin-left: auto; margin-right: auto;\"}\n<br>\n<small>[Artwork by @allison_horst](https://x.com/allison_horst)</small>\n</div>\n\n## Making data wider with `pivot_wider()`\n* To convert data from long format to wide/messy format use`pivot_wider()`.\n* For example, let's try creating a column for each time value in `cases_df`:\n\n<!-- Example. Spreadsheet from hell -->\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmessy_cases_df <- cases_df |>\n  pivot_wider(\n    names_from = time_value,   # Create new columns for each unique date\n    values_from = raw_cases    # Fill those columns with the raw_case values\n  )\n\n# View the result\nmessy_cases_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 32\n  geo_value `2022-03-01` `2022-03-02` `2022-03-03` `2022-03-04` `2022-03-05`\n  <chr>            <dbl>        <dbl>        <dbl>        <dbl>        <dbl>\n1 ca                4310         7044         7509         3586         1438\n2 nc                1231         2243         2377         2646            0\n3 ny                1487         1889         2390          350         3372\n# ℹ 26 more variables: `2022-03-06` <dbl>, `2022-03-07` <dbl>,\n#   `2022-03-08` <dbl>, `2022-03-09` <dbl>, `2022-03-10` <dbl>,\n#   `2022-03-11` <dbl>, `2022-03-12` <dbl>, `2022-03-13` <dbl>,\n#   `2022-03-14` <dbl>, `2022-03-15` <dbl>, `2022-03-16` <dbl>,\n#   `2022-03-17` <dbl>, `2022-03-18` <dbl>, `2022-03-19` <dbl>,\n#   `2022-03-20` <dbl>, `2022-03-21` <dbl>, `2022-03-22` <dbl>,\n#   `2022-03-23` <dbl>, `2022-03-24` <dbl>, `2022-03-25` <dbl>, …\n```\n\n\n:::\n:::\n\n\n\n##  Tidying messy data with `pivot_longer()`\n* Use `pivot_longer()` to convert data from [**wide format**]{.primary} (multiple columns for the same variable) to [**long format**]{.primary} (one column per variable).\n* Let's try turning `messy_cases_df` back into the original tidy `cases_df`!\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy_cases_df <- messy_cases_df |>\n  pivot_longer(\n    cols = -geo_value,          # Keep the 'geo_value' column as it is\n    names_to = \"time_value\",    # Create a new 'time_value' column from the column names\n    values_to = \"raw_cases\"     # Values from the wide columns should go into 'raw_cases'\n  )\n\n# View the result\nhead(tidy_cases_df, n = 3) # Notice the class of time_value here\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  <chr>     <chr>          <dbl>\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03      7509\n```\n\n\n:::\n:::\n\n\n\n##  Tidying messy data with `pivot_longer()`\n\n* When we used `pivot_longer()`, the `time_value` column is converted to a character class because the column names are treated as strings.\n* So, to truly get the original `cases_df` we need to convert `time_value` back to the `Date` class.\n* Then, we can use `identical()` to check if the two data frames are exactly the same.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy_cases_df = tidy_cases_df |> mutate(time_value = as.Date(time_value))\n\nidentical(tidy_cases_df |> arrange(time_value), cases_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\nGreat. That was a success!\n\n## Missing data\n* Sometimes you may have missing data in your time series.\n* Can be due to actual missing data, or it can be due to the fact that the data is only reported on certain days.\n* Let's create a dataset with missing data & consider each of those cases:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nca_missing <- cases_df |>\n  filter(geo_value == \"ca\") |>\n  slice(1:2, 4:6) # Subset rows 1 to 2 and 4 to 6; ie. omit 2022-03-03\n\nca_missing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-04      3586\n4 ca        2022-03-05      1438\n5 ca        2022-03-06      6465\n```\n\n\n:::\n:::\n\n\n\n## `complete()` and `fill()` to handle missing data\n\nA simple workflow to handle missing data relies on one or both of these functions:\n\n1. `complete()`: Adds missing rows for combinations of specified variables.\n\n2. `fill()`: Fills missing values in columns, typically from previous or next available values (default is LOCF).\n\n## Data only reported on certain days\n\n* If the data is only reported on certain days, it is often useful to fill in the missing data with explicit zeros.\n* `complete()` is enough to handle this:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# First, use complete() to add missing time_value (2022-03-03)\nca_complete <- ca_missing |>\n  complete(geo_value, time_value = seq(min(time_value), max(time_value), by = \"day\"),\n           fill = list(raw_cases = 0))\nca_complete\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03         0\n4 ca        2022-03-04      3586\n5 ca        2022-03-05      1438\n6 ca        2022-03-06      6465\n```\n\n\n:::\n:::\n\n\n<!-- Using complete(time_value) doesn't work as expected because it doesn't automatically generate a sequence of missing dates between the min and max values of time_value. Instead, it simply tries to match the unique values in time_value and doesn't infer a complete range. To ensure complete() does what you want for time, it is best practice to explicitly create a sequence of dates that covers the entire range of time_value. -->\n\n## Data is genuinely missing\n\n* If the data is truly missing, then there are multiple options (ex. omission, single imputation, multiple imputation).\n* A common single imputation method  used to handle missing data in time series or longitudinal datasets is LOCF.\n* We can easily perform LOCF using `complete()` followed by `fill()`.\n* Start with `complete()`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# First, use complete() to add missing time_value (2022-03-03)\nca_complete <- ca_missing |>\n  complete(geo_value, time_value = seq(min(time_value), max(time_value), by = \"day\"))\nhead(ca_complete, n = 4) # notice no fill with 0s this time, NA by default\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03        NA\n4 ca        2022-03-04      3586\n```\n\n\n:::\n:::\n\n\n\n## Data is genuinely missing\nThen, use `fill()` to fill the counts using LOCF (default):\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nca_complete |>\n  fill(raw_cases)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-01      4310\n2 ca        2022-03-02      7044\n3 ca        2022-03-03      7044\n4 ca        2022-03-04      3586\n5 ca        2022-03-05      1438\n6 ca        2022-03-06      6465\n```\n\n\n:::\n:::\n\n\n\n## Introduction to joins in `dplyr`\n* Joining datasets is a powerful tool for combining info. from multiple sources.\n* In R, `dplyr` provides several functions to perform different types of joins.\n* We'll demonstrate joining a subset of `cases_df` (our case counts dataset) with `state_census`.\n* [**Motivation**]{.primary}: We can scale the case counts by population to make them comparable across regions of different sizes.\n\n## Subset `cases_df`\n\nTo simplify things, let's use `filter()` to only grab one date of `cases_df`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncases_df_sub = cases_df |> filter(time_value == \"2022-03-01\")\ncases_df_sub\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  geo_value time_value raw_cases\n  <chr>     <date>         <dbl>\n1 ca        2022-03-01      4310\n2 nc        2022-03-01      1231\n3 ny        2022-03-01      1487\n```\n\n\n:::\n:::\n\n\n\nThough note that what we're going to do can be applied to the entirety of `cases_df`.\n\n## Load state census data\n\nThe `state_census` dataset from `epidatasets` contains state populations from the 2019 census.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# State census dataset from epidatasets\nlibrary(epidatasets)\nstate_census = state_census |> select(abbr, pop) |> filter(abbr != \"us\")\n\nstate_census |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  abbr       pop\n  <chr>    <dbl>\n1 al     4903185\n2 ak      731545\n3 az     7278717\n4 ar     3017804\n5 ca    39512223\n6 co     5758736\n```\n\n\n:::\n:::\n\n\n\nNotice that this includes many states that are not in `cases_df_sub`.\n\n## Left Join: Keep all rows from the first dataset\n\n* A [**left join**]{.primary} keeps all rows from the [**first dataset**]{.primary} (`cases_df_sub`), and adds matching data from the second dataset (`state_census`).\n* So [**all rows from the first dataset**]{.primary} (`cases_df_sub`) will be preserved.\n* The datasets are joined by matching the `geo_value` column, specified by the by argument.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Left join: combining March 1, 2022 state case data with the census data\ncases_left_join <- cases_df_sub |>\n  left_join(state_census, join_by(geo_value == abbr))\n\ncases_left_join\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  <chr>     <date>         <dbl>    <dbl>\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n```\n\n\n:::\n:::\n\n\n\n## Right Join: Keep all rows from the second dataset\n* A [**right join**]{.primary} keeps all rows from the [**second dataset**]{.primary} (`state_census`), and adds matching data from the first dataset (`cases_df_sub`).\n* If a row in the second dataset doesn't have a match in the first, then the columns from the first will be filled with NA.\n* For example, can see this for the `al` row from `state_census`...\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Right join: keep all rows from state_census\ncases_right_join <- cases_df_sub |>\n  right_join(state_census, join_by(geo_value == abbr))\n\nhead(cases_right_join)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  <chr>     <date>         <dbl>    <dbl>\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717\n```\n\n\n:::\n:::\n\n\n\n## Inner Join: Only keeping matching rows\n* An [**inner join**]{.primary} will only keep rows where there is a match in both datasets.\n* So, if a state in `state_census` does not have a corresponding entry in `cases_df_sub`, then that row will be excluded.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Inner join: only matching rows are kept\ncases_inner_join <- cases_df_sub |>\n  inner_join(state_census, join_by(geo_value == abbr))\n\ncases_inner_join\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  geo_value time_value raw_cases      pop\n  <chr>     <date>         <dbl>    <dbl>\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n```\n\n\n:::\n:::\n\n\n\n## Full Join: Keeping all rows from both datasets\n\n* A [**full join**]{.primary} will keep all rows from both datasets.\n* If a state in either dataset has no match in the other, the missing values will be filled with NA.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Full join: keep all rows from both datasets\ncases_full_join <- cases_df_sub |>\n  full_join(state_census, join_by(geo_value == abbr))\n\nhead(cases_full_join)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  geo_value time_value raw_cases      pop\n  <chr>     <date>         <dbl>    <dbl>\n1 ca        2022-03-01      4310 39512223\n2 nc        2022-03-01      1231 10488084\n3 ny        2022-03-01      1487 19453561\n4 al        NA                NA  4903185\n5 ak        NA                NA   731545\n6 az        NA                NA  7278717\n```\n\n\n:::\n:::\n\n\n\n## Pictorial summary of the four join functions\n\n<!--* **Left join:** All rows from the left dataset and matching rows from the right dataset.\n* **Right join:** All rows from the right dataset and matching rows from the left dataset.\n* **Inner join:** Only matching rows from both datasets.\n* **Full join:** All rows from both datasets, with NA where no match exists.-->\n\n![](gfx/join_funs_cheatsheet.png){style=\"width: 40%; display: block; margin-left: auto; margin-right: auto;\"}\n<div style=\"text-align: center;\">\n<small>[Source](https://ohi-science.org/data-science-training/dplyr.html)</small>\n</div>\n\n## Final thoughts on joins\n* Joins are an essential part of data wrangling in R.\n* The choice of join depends on the analysis you need to perform:\n    + Use [**left joins**]{.primary} when you want to keep all data from the first dataset.\n    + Use [**right joins**]{.primary} when you want to keep all data from the second dataset.\n    + Use [**inner joins**]{.primary} when you're only interested in matching rows.\n    + Use [**full joins**]{.primary} when you want to preserve all information from both datasets.\n\n## Three review questions\n\n**Q1)**: What can we use to fill in the missing `time_value` for the states in `cases_full_join`?\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ncases_full_join |>\n     fill(time_value)\n```\n:::\n\n\n**Q2)**: Now, what join function should you use if your goal is to scale the cases by population in `cases_df`?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Either left_join\ncases_left_join <- cases_df |>\n  left_join(state_census, join_by(geo_value == abbr))\n\ncases_left_join\ncases_df = cases_left_join\n\n# Or inner_join\ncases_inner_join <- cases_df |>\n  inner_join(state_census, join_by(geo_value == abbr))\n\ncases_inner_join\n```\n:::\n\n\n\n**Q3)**: Finally, please create a new column in `cases_df` where you scale the cases by population and multiply by `1e5` to get cases / 100k.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ncases_df <- cases_df |>\n  mutate(scaled_cases = raw_cases / pop * 1e5) # cases / 100K\nhead(cases_df)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}